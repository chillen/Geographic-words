{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from wordtrackingmodels import WordModelCollection\n",
    "import json\n",
    "import csv\n",
    "import re\n",
    "import glob\n",
    "import math\n",
    "from collections import Counter\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {1: [1, 2, 3], 2: [2, 3, 4]})"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {1: [1,2,3], 2: [2,3,4]}\n",
    "dd = defaultdict(list)\n",
    "for k in d:\n",
    "    dd[k] = d[k]\n",
    "dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def loadFile(f):\n",
    "    lines = []\n",
    "    text = []\n",
    "    with open(f, mode='r') as infile:\n",
    "        lines = infile.readlines()\n",
    "    started = False\n",
    "    ended = False\n",
    "    for line in lines:\n",
    "        if not started:\n",
    "            if '*** START' in line or '***START' in line:\n",
    "                started = True\n",
    "            continue\n",
    "        if '*** END' in line or '***END' in line:\n",
    "            break\n",
    "        line = line.strip('\\n')\n",
    "        line = unicode(line, \"ascii\", errors=\"ignore\")\n",
    "        line =  re.sub(\"[^a-zA-Z]\", \" \", line)\n",
    "        line = line.lower()\n",
    "        text.extend(line.split())\n",
    "    text = \" \".join([w for w in text if suitableWord(w)])\n",
    "    return text\n",
    "\n",
    "def suitableWord(word):\n",
    "    if len(word) < 2:\n",
    "        return False\n",
    "    if word in stops:\n",
    "        return False\n",
    "    if word not in english:\n",
    "        return False\n",
    "    if word in warriner and warriner[word]['arousal'] < 4:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def dbg(*message):\n",
    "    \"\"\"Print a debug message if debugging is on.\"\"\"\n",
    "    if not debugging:\n",
    "        return False\n",
    "    message = [str(m) for m in message]\n",
    "    print '  [DBG] ', ''.join(message)\n",
    "\n",
    "def loadModels(maxmodels=-1):\n",
    "    models = []\n",
    "    files = glob.glob('data/*.txt')\n",
    "    maxmodels = maxmodels if maxmodels >0 else len(files)\n",
    "    for i, f in enumerate(files[:maxmodels]):\n",
    "        meta = getGutenbergMeta(f)\n",
    "        dbg( '['+str(i)+'] Currently processing ', meta['title'], '...')\n",
    "        models.append({'text': loadFile(f), 'meta': meta})\n",
    "    return models\n",
    "\n",
    "def loadWarriner():\n",
    "    warriner = {}\n",
    "    with open('models/warriner.csv', mode='r') as infile:\n",
    "        reader = csv.reader(infile)\n",
    "        next(reader)\n",
    "        warriner = {rows[1]: {'valence': (float)(rows[2]), 'arousal': (float)(rows[5]), 'dominance': (float)(rows[8])} for rows in reader}\n",
    "    return warriner\n",
    "\n",
    "def getGutenbergMeta(f):\n",
    "    data = {}\n",
    "    with open(f) as infile:\n",
    "        for line in infile.readlines():\n",
    "            if line.startswith('Title: '):\n",
    "                data['title'] = unicode(line[len('Title: '):].strip('\\n'), \"ascii\", errors=\"ignore\")\n",
    "            if line.startswith('Author: '):\n",
    "                data['author'] = unicode(line[len('Author: '):].strip('\\n'), \"ascii\", errors=\"ignore\")\n",
    "    return data\n",
    "\n",
    "def findClustersForWord(search, models, dist_away=2, exclusive=True):\n",
    "    near = dist_away\n",
    "    clusters = {}\n",
    "    similarclusters = []\n",
    "    for model in models:\n",
    "        clusters[model] = set([word for word in models[model].getNearbyWordsInRange(search, near)])\n",
    "        similarclusters = []\n",
    "        for cluster1 in clusters:\n",
    "            for cluster2 in clusters:\n",
    "                if cluster1 != cluster2:\n",
    "                    if len(clusters[cluster1] & clusters[cluster2]) > 2:\n",
    "                        newclust = ((cluster1, clusters[cluster1]), (cluster2, clusters[cluster2]))\n",
    "                        if (newclust[1], newclust[0]) not in similarclusters:\n",
    "                            similarclusters.append(newclust)\n",
    "    if not exclusive:\n",
    "        return similarclusters\n",
    "    else:\n",
    "        return [((cluster[0][0], cluster[1][0]), cluster[0][1] & cluster[1][1] )for cluster in similarclusters]\n",
    "def modelSimilarToWord(model, word, textlength, wordset):\n",
    "    return 1000*math.log(1+model.getWord(word).getCount()/float(textlength))\n",
    "    \n",
    "def modelsMostSimilarToTerms(models, search):\n",
    "    if isinstance(search, str): \n",
    "        search = [search]\n",
    "    similars = {}\n",
    "    for title in models:\n",
    "        similars[title] = Counter()\n",
    "        model = models[title]\n",
    "        text = model.getText()\n",
    "        numwords = len(text.split())\n",
    "        wordset = set(text.split())\n",
    "        for word in search:\n",
    "            if word in wordset:\n",
    "                similars[title].update({word: modelSimilarToWord(model, word, numwords, wordset)})\n",
    "    sortedsums = sorted([(sum(similars[title].values()), title, similars[title].items()) for title in similars if len(similars[title].items()) != 0], reverse=True)\n",
    "    return sortedsums\n",
    "def findCommonClusters(models, dist_away=2, exclusive=True):\n",
    "    wordsets = [set(models[title].getText().split()) for title in models]\n",
    "    n = len(models)\n",
    "    commonwords = set.intersection(*wordsets)\n",
    "    commonclusters = {}\n",
    "    for word in commonwords:\n",
    "        found = findClustersForWord(word, models, dist_away, exclusive)\n",
    "        if len(found) > 0:\n",
    "            if word not in commonclusters:\n",
    "                commonclusters[word] = []\n",
    "            commonclusters[word].extend(found)\n",
    "    # If there is n choose 2 entries, then all of them have commonalities with each other\n",
    "    commonclusters = {word: commonclusters[word] for word in commonclusters if len(commonclusters[word]) >= n * (n-1) / 2}\n",
    "    return commonclusters\n",
    "def findCommonWordsInClusters(models, dist_away=2, exclusive=True, join='union'):\n",
    "    commonclusters = findCommonClusters(models, dist_away, exclusive)\n",
    "    wordsets = {}\n",
    "    for word in commonclusters:\n",
    "        wordsets[word] = commonclusters[word][0][1]\n",
    "        for l in commonclusters[word]:\n",
    "            if join == 'union':\n",
    "                wordsets[word] = wordsets[word] | l[1]\n",
    "            if join == 'intersection':\n",
    "                wordsets[word] = wordsets[word] & l[1]\n",
    "        if len(wordsets[word]) == 0:\n",
    "            del wordsets[word]\n",
    "    return wordsets\n",
    "\n",
    "debugging = False\n",
    "warriner = loadWarriner()\n",
    "stops = set(json.load(open('data/nltkstopwords.json', 'r')))\n",
    "english = set(json.load(open('data/english.json', 'r')))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "collect = WordModelCollection()\n",
    "meta = getGutenbergMeta('data/dracula.txt')\n",
    "text = loadFile('data/dracula.txt')\n",
    "collect.updateModel(text, meta)\n",
    "models = loadModels(maxmodels=5)\n",
    "for model in models:\n",
    "    collect.updateModel(model['text'], model['meta'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
